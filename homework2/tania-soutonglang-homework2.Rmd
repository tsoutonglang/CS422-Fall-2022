---
title: "CS 422 Homework 2"
author: "Tania Soutonglang"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

### 2.1

```{r}
library(ISLR)
data(Auto)

set.seed(1122)
index <- sample(1:nrow(Auto), 0.95*dim(Auto)[1])
train.df <- Auto[index,]
test.df <- Auto[-index, ]
```

### 2.1-a

```{r}
autoModel <- lm(mpg ~ . -name, data = test.df)
```

#### 2.1-a-i

Using name is not a good predictor because not all values in the data set would have a similar or the same pattern of letters to make a comparison without creating biased data.

#### 2.1-a-ii

```{r}
summary(autoModel)

rss <- round(sum(autoModel$residuals^2), digit = 2)

# rse <- round(sqrt(mean(autoModel$residuals^2)), digit = 2)

rmse <- round(sqrt(mean(autoModel$residuals^2)), digit = 2)
rmse

str <- cat(paste0("R-sq value is 0.93\nAdjusted R-sq value is 0.92\nRSE is 2.47\nRMSE is ", rmse))
```

#### 2.1-a-iii

```{r}
autoRes <- autoModel$residuals

plot(fitted(autoModel), autoRes, main = "2.1-a-iii Auto Model Residuals", xlab = "Model", ylab = "Residuals")
```

#### 2.1-a-iv

```{r}
hist(autoRes, main = "2.1-a-iv Auto Module Residuals", xlab = "Residuals")
```

This histogram does not follow a Gaussian distribution. The distribution of the residuals are primarily either below the regression line or near/on the regression line.

### 2.1-b
#### 2.1-b-i

According to the regression model made in part (a), weight, year, and acceleration are statistically significant.

```{r}
autoNewModel <- lm(mpg ~ weight + year + acceleration, data = test.df)
```

#### 2.1-b-ii

```{r}
summary(autoNewModel)

rmse <- round(sqrt(mean(autoNewModel$residuals^2)), digits = 2)

str <- cat(paste0("R-sq value is 0.93\nRSE is 2.30\nRMSE is ", rmse))
```

The new model's values of R2, RSE, and RMSE did not change too much from the original model.

#### 2.1-b-iii

```{r}
autoNewRes <- autoNewModel$residuals

plot(fitted(autoNewModel), autoNewRes, main = "2.1-b-iii Auto Model Residuals", xlab = "Model", ylab = "Residuals")
```

#### 2.1-b-iv

```{r}
hist(autoNewRes, main = "2.1-b-iv Auto Module Residuals", xlab = "Residuals")
```

This histogram does not follow a Gaussian distribution. The distribution of the residuals are vary a lot throughout the model.

#### 2.1-b-v
The new model would be better since the data is more centralized towards the attributes with significantly smaller p-values, indicating a smaller margin of error in the data.

### 2.1-c
```{r}
library(dplyr)

df <- data.frame(
  Prediction = c(predict(autoNewModel)),
  Response = c(test.df %>% select(mpg))
)
```

### 2.1-d
```{r}
dfConfidence <- df
ConfidenceInt <- predict(autoNewModel, interval = 'confidence')

my_fun <- function(x) {
  if (dfConfidence[x,2] > ConfidenceInt[x, 2]) {
    if (dfConfidence[x,2] < ConfidenceInt[x, 3]) {
      return(1)
    } # response in CI
    else {
      return(0)
    } # response not in CI
  }
  else{
    return(1)
  } # response not in CI
}

Matches <- c(sapply(seq_len(nrow(dfConfidence)), my_fun))

dfConfidence['Lower'] <- c(ConfidenceInt[,2])
dfConfidence['Upper'] <- c(ConfidenceInt[,3])
dfConfidence['Matches'] <- Matches
dfConfidence

str <- paste0("Total observations correctly predicted: ", nrow(dfConfidence %>% filter(Matches == 1)))
str
```

### 2.1-e
```{r}
dfPredict <- df
PredictInt <- predict(autoNewModel, interval = 'predict')

my_fun <- function(x) {
  if (dfPredict[x,2] > PredictInt[x, 2]) {
    if (dfPredict[x,2] < PredictInt[x, 3]) {
      return(1)
    } # response in CI
    else {
      return(0)
    } # response not in CI
  }
  else{
    return(1)
  } # response not in CI
}

Matches <- c(sapply(seq_len(nrow(dfPredict)), my_fun))

dfPredict['Lower'] <- c(PredictInt[,2])
dfPredict['Upper'] <- c(PredictInt[,3])
dfPredict['Matches'] <- Matches
dfPredict

str <- paste0("Total observations correctly predicted: ", nrow(dfPredict %>% filter(Matches == 1)))
str
```

### 2.1-f
#### 2.1-f-i
The results of (e) showed that all 20 rows had a match whereas (d) only had 16 matches.

#### 2.1-f-ii
This was likely because the prediction interval would have accounted for the uncertainty for the future and any variations that may occur.